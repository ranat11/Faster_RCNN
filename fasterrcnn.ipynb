{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from PIL import Image\n",
    "import json\n",
    "\n",
    "class CreateDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, info_dir, img_dir, transforms=None):\n",
    "        with open(info_dir) as f:\n",
    "            info = json.load(f)\n",
    "            self.data_info = info[\"annotations\"]\n",
    "\n",
    "        self.img_dir = img_dir\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, str(self.data_info[idx][\"id\"])+\".png\")\n",
    "        img = Image.open(img_path)\n",
    "        \n",
    "        info = self.data_info[idx]\n",
    "\n",
    "        image_id = info[\"id\"]\n",
    "        num_objs = len(info[\"category_id\"])\n",
    "        iscrowd = info[\"iscrowd\"]\n",
    "\n",
    "        boxes = []\n",
    "        labels = []\n",
    "        for i in range(num_objs):\n",
    "            box = info[\"bbox\"][i]\n",
    "            xmin = np.min(box[0])\n",
    "            xmax = np.max(box[0]+box[2])\n",
    "            ymin = np.min(box[1])\n",
    "            ymax = np.max(box[1]+box[3])\n",
    "            boxes.append([xmin, ymin, xmax, ymax])\n",
    "\n",
    "            labels.append(info[\"category_id\"][i]-1)                 \n",
    "\n",
    "        image_id = torch.tensor([image_id])\n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        labels = torch.as_tensor(labels, dtype=torch.int64)\n",
    "        iscrowd = torch.zeros((num_objs,), dtype=torch.int64)\n",
    "\n",
    "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
    "        target = {}\n",
    "        target[\"boxes\"] = boxes\n",
    "        target[\"labels\"] = labels\n",
    "        target[\"image_id\"] = image_id\n",
    "        target[\"area\"] = area\n",
    "        target[\"iscrowd\"] = iscrowd\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            img, target = self.transforms(img, target)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<PIL.PngImagePlugin.PngImageFile image mode=RGB size=1080x1920 at 0x7FD7CC6796D0>,\n",
       " {'boxes': tensor([[ 417.5385, 1134.7693,  686.7692, 1320.9231],\n",
       "          [ 322.1538, 1325.5385,  746.7692, 1917.8462]]),\n",
       "  'labels': tensor([3, 0]),\n",
       "  'image_id': tensor([20201111123018241]),\n",
       "  'area': tensor([ 50118.3320, 251502.9844]),\n",
       "  'iscrowd': tensor([0, 0])})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = CreateDataset('datasets/info_all.json', 'datasets/images')\n",
    "dataset[150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from engine import train_one_epoch, evaluate\n",
    "import utils\n",
    "import transforms as T\n",
    "\n",
    "#TODO\n",
    "def get_transform(train):\n",
    "    transforms = []\n",
    "    # converts the image, a PIL image, into a PyTorch Tensor\n",
    "    transforms.append(T.ToTensor())\n",
    "    if train:\n",
    "        transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "    return T.Compose(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CreateDataset('datasets/info_all.json', 'datasets/images', get_transform(train=True))\n",
    "val_dataset = CreateDataset('datasets/info_all.json', 'datasets/images', get_transform(train=False))\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "indices = torch.randperm(len(train_dataset)).tolist()\n",
    "split_idx = int(0.1*len(train_dataset))\n",
    "train_dataset = torch.utils.data.Subset(train_dataset, indices[:-split_idx])\n",
    "val_dataset = torch.utils.data.Subset(val_dataset, indices[-split_idx:])\n",
    "\n",
    "# define training and validation data loaders\n",
    "BATCH_SIZE = 16\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, collate_fn=utils.collate_fn, drop_last=True) \n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, collate_fn=utils.collate_fn, drop_last=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## test code\n",
    "\n",
    "# data_loader = torch.utils.data.DataLoader(train_dataset, batch_size=2, shuffle=True, num_workers=4, collate_fn=utils.collate_fn)\n",
    "# images, targets = next(iter(data_loader))\n",
    "# images = list(image for image in images)\n",
    "# targets = [{k: v for k, v in t.items()} for t in targets]\n",
    "# output = model(images,targets)   # Returns losses and detections\n",
    "\n",
    "# model.eval()\n",
    "# x = [torch.rand(3, 300, 400), torch.rand(3, 500, 400)]\n",
    "# predictions = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "\n",
    "num_classes = 4\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes) \n",
    "model.to(device)\n",
    "\n",
    "# construct an optimizer\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.1, patience=2, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ranat/miniconda3/envs/ml/lib/python3.9/site-packages/torch/autocast_mode.py:141: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    }
   ],
   "source": [
    "LOAD_MODEL = False\n",
    "LOAD_MODEL_FILE = \"model/default.pth\"\n",
    "\n",
    "if LOAD_MODEL:\n",
    "    print(\"=> Loading checkpoint\")\n",
    "    checkpoint = torch.load(LOAD_MODEL_FILE)\n",
    "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
    "\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    train_one_epoch(model, optimizer, train_loader, device, epoch, print_freq=10)\n",
    "    lr_scheduler.step()\n",
    "    evaluate(model, val_loader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"saving model\")\n",
    "save_model = {\"state_dict\": model.state_dict(), \"optimizer\": optimizer.state_dict()}\n",
    "torch.save(save_model, LOAD_MODEL_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, _ = val_dataset[2]\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    prediction = model([img.to(device)])\n",
    "\n",
    "print(prediction)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "adc0be9a0823af992138c3f6ff0b75f39a31027a17f52ddaaa57998d3b0f14f8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('ml': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
